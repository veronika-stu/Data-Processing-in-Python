{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Introduction\n",
    "\n",
    "**Week 9**, April 14, 2025\n",
    "\n",
    "Lecture: Regression, Classification, Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Data Science?\n",
    "\n",
    "- **Data Science** involves extracting meaningful insights from large datasets using various tools and techniques. It includes data collection, cleaning, processing, analysis, and visualization.\n",
    "- For **economists**, data science can be used to understand economic trends, analyze policy impacts, forecast future economic conditions, and make data-driven decisions.\n",
    "\n",
    "## The Role of Python in Data Science\n",
    "\n",
    "- Python is a versatile programming language with powerful libraries (e.g., Pandas, NumPy, Matplotlib, Scikit-learn) that make data processing, analysis, and visualization more accessible and efficient.\n",
    "- Python allows economists to automate data processing tasks and create reproducible workflows, which is important for ensuring accuracy and consistency in economic research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Pipeline in Economics\n",
    "\n",
    "### 1: Importing and Cleaning Data\n",
    "\n",
    "- Import data from various sources (CSV, Excel, databases) and perform basic cleaning, such as removing duplicates, handling missing values, and formatting data types.\n",
    "    - **Example**: Import and clean a dataset on inflation rates or unemployment figures.\n",
    "\n",
    "### 2: Exploratory Data Analysis (EDA)\n",
    "\n",
    "- **EDA** involves summarizing the data, identifying patterns, and visualizing distributions. This is an important step to gain insights before performing more advanced analyses.\n",
    "    - **Example**: Plot the distribution of unemployment rates across different countries to detect patterns or outliers.\n",
    "\n",
    "### 3: Statistical Analysis\n",
    "\n",
    "- Conduct statistical analyses to test hypotheses. Economists often perform tests like t-tests, chi-square tests, or ANOVA to understand the relationships between economic variables.\n",
    "    - **Example**: Testing the hypothesis that a country's unemployment rate is significantly correlated with its GDP growth.\n",
    "\n",
    "### 4: Building and Evaluating Models\n",
    "\n",
    "- Use machine learning models (e.g., linear regression, decision trees) to predict or classify economic outcomes.\n",
    "    - **Example**: Forecasting inflation based on historical data or predicting economic growth using a set of features (investment, government spending).\n",
    "\n",
    "### 5: Visualization and Reporting\n",
    "\n",
    "- Create effective visualizations (e.g., line graphs, bar charts, scatter plots) and generate reports to communicate your findings clearly.\n",
    "    - **Example**: Create a report that outlines the predicted GDP growth for the next year based on the current dataset, with supporting visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Considerations for Economists and Economics Students\n",
    "\n",
    "- Data Quality and Reliability\n",
    "  - **Economists must ensure the quality of their data**, as poor data leads to misleading conclusions. This involves cleaning the data, checking for biases, and ensuring that the sources are reliable.\n",
    "      - **Important**: Be cautious about data collection methods (e.g., surveys, government reports) and consider potential sources of bias (e.g., non-response bias).\n",
    "\n",
    "- Interpreting Results\n",
    "  - **Contextualizing Results**: It's crucial for economists to interpret the results of data analysis in the context of economic theory and real-world dynamics. For instance, predicting GDP growth isn't just about fitting a model but understanding the underlying economic forces.\n",
    "  - **Model Limitations**: Models may be useful for prediction but don't always capture all nuances of the economic reality. Be aware of overfitting, underfitting, and the assumptions underlying models.\n",
    "\n",
    "- Ethical Considerations\n",
    "  - **Ethical Use of Data**: Economists should be aware of the ethical implications of using data, especially when working with sensitive information. Issues like data privacy, fairness, and transparency should be considered.\n",
    "\n",
    "- Reproducibility\n",
    "  - **Reproducible Workflows**: All analyses should be reproducible, meaning someone else with access to the same data and code can replicate your results. This is essential for ensuring the credibility of economic research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Python as a \"go-to\" language for data science (DS) / machine learning because of its (open-source) libraries\n",
    "* we've seen `pandas` for powerful data manipulation and `numpy` for numerical computations, but this is far from what Python has to offer for DS\n",
    "* we need tools for typical DS tasks such as **Regression**, **Classification**, **Clustering**\n",
    "\n",
    "* to name a few data-science libraries (in no particular order)\n",
    "    * [scikit-learn]()\n",
    "        * supervised vs. unsupervised learning\n",
    "        * validation \n",
    "        * evaluation\n",
    "        * CPU optimized\n",
    "\n",
    "    * [scipy]()\n",
    "        * optimization algorithms\n",
    "        * statistics\n",
    "        * fourier transforms\n",
    "\n",
    "    * [torch]() / [tensorflow]() (+ [keras]())\n",
    "        * neural networks\n",
    "        * GPU optimized \n",
    "        * state-of-the-art for NLP/vision/...\n",
    "    * [lightgbm]() / [xgboost]() / [catboost]()\n",
    "        * tree methods\n",
    "        * state-of-the-art for tabular datasets\n",
    "\n",
    "* we will look at scikit-learn and lightgbm using some [toy datasets](https://scikit-learn.org/stable/datasets/toy_dataset.html)\n",
    "\n",
    "* we will not focus on the algorithmic/estimation part of the models but on the programming side\n",
    "\n",
    "* [mlflow](https://mlflow.org/) is a great platform which can help you in different parts of your ML/DS lifecycle, e.g.\n",
    "    * tracking experiments\n",
    "    * package DS projects\n",
    "    * register and deploy trained models\n",
    "\n",
    "* [kaggle](https://www.kaggle.com/) great resource to see the state-of-the-art approaches and methods to different problems\n",
    "\n",
    "* [huggingface.io](https://huggingface.co) machine learning models and data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn \n",
    "import sklearn.datasets\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "import lightgbm\n",
    "import matplotlib.pyplot as plt\n",
    "# retina matplotlib for better quality plots\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn \n",
    "\n",
    "* contains implementations of a number of ML algorithms - called **estimators**\n",
    "* estimators typically have a standardized method names / attributes - e.g. `.fit()` and `.predict()` methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression (California housing)\n",
    "\n",
    "* was going to use [boston housing prices dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset), which is a standard but apparently there are some [ethical concerns]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.datasets.load_boston()['DESCR'];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we will use California house prices dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.datasets.fetch_california_housing().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = sklearn.datasets.fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_raw['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.datasets.fetch_california_housing()['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.Series(data_raw['target'], name = data_raw['target_names'][0]) # target is the median house value for California districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_raw['data'], columns = data_raw['feature_names']) # predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(11, 7), bins=25, edgecolor=\"black\")\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We want to be able to predict the prices of unseen houses\n",
    "    - \"explainning\"/overfitting the already seen data is very easy with high capacity models (e.g. trees, neural nets, etc.)\n",
    "- To achieve this, we usually split the available data according to some validation scheme\n",
    "- Validation scheme needs to respect the nature of a forecasting problem \n",
    "    - cross-validation \n",
    "    - temporal validation\n",
    "\n",
    "- You can use `sklearn` validation utils for standard tasks or write your own for more exotic\n",
    "- Don't forget to set `random_state` so that your results can be reproduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_of_interest = [\"AveRooms\", \"AveBedrms\", \"AveOccup\", \"Population\"]\n",
    "df[features_of_interest].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could make a scatter plot where the x- and y-axis would be the latitude and longitude and the circle size and color would be linked with the house value in the district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "california_housing = sklearn.datasets.fetch_california_housing(as_frame=True)\n",
    "california_housing.frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # our previous dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "california_housing.frame[\"MedHouseVal\"].hist() # the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.scatterplot(\n",
    "    data=california_housing.frame,\n",
    "    x=\"Longitude\",\n",
    "    y=\"Latitude\",\n",
    "    size=\"MedHouseVal\",\n",
    "    hue=\"MedHouseVal\",\n",
    "    palette=\"viridis\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.legend(title=\"MedHouseVal\", bbox_to_anchor=(1.05, 0.95), loc=\"upper left\")\n",
    "_ = plt.title(\"Median house value depending of\\n their spatial location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple random split using sklearn\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(df, label, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape, X_train.shape, X_test.shape);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Machine learning models have number of hyperparameters that need to be tweaked\n",
    "    - searching for optimal using only in-sample (seen) data not good\n",
    "    - using test-set from above leads to \"overfitting\" on the test set\n",
    "- Typical solution is to introduce so called validation set used only for evaluating hyperparameters\n",
    "    - splitting dataset into 3 parts however makes our dataset we can learn from drastically smaller \n",
    "- Cross-validation (or temporal validation)\n",
    "    - cross validation iterators are handy and return the indices of the original dataframes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf5 = sklearn.model_selection.KFold(n_splits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df, label], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for train_idx, test_idx in kf5.split(data):\n",
    "\n",
    "    print(f'Split no. {i}')\n",
    "    print(train_idx, test_idx)\n",
    "\n",
    "    train_data = data.loc[train_idx,:]\n",
    "    test_data = data.loc[test_idx,:]\n",
    "    i=i+1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Typical situation arises when you need to respect certain classes/groups in the data during splitting process\n",
    "    * use `GroupKFold` data for this\n",
    "* To respect time-series nature of the problem, you can use `TimeSeriesSplit`\n",
    "\n",
    "\n",
    "* We want to fit the model using the train data in each fold and predict the test data in each fold\n",
    "    * we can start with the simplest \"model\" -> sample mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'MedHouseVal'\n",
    "kf_predictions = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "for train_idx, test_idx in kf5.split(data):\n",
    "    print(f'split no. {i}')\n",
    "    train_data = data.loc[train_idx,:]\n",
    "    test_data = data.loc[test_idx,:]\n",
    "\n",
    "    # \"fitting\" part\n",
    "    sample_mean = train_data[label].mean()\n",
    "    # prediction part \n",
    "    test_data['prediction'] = sample_mean\n",
    "\n",
    "    # save predictions\n",
    "    test_data['split'] = i\n",
    "    kf_predictions = pd.concat([kf_predictions, test_data], axis = 0)\n",
    "    i = i + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have our first predictions, even though simple ones\n",
    "- NOTE: when you have large data that don't fit into RAM, you can do the forecasting/predicting \"lazily\"\n",
    "    - save individual split results or save only split-metrics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "- regression task:\n",
    "    - typically MSE, MAE, MAPE, wMAPE or r2\n",
    "- evaluation strategy should take into account what stakeholder wants, the kitchen-sink approach not recommended\n",
    "- we are interested in out-of-sample!\n",
    "    - sometimes it is interesting to look at in-sample and compare errors in-sample vs out-of-sample\n",
    "- scikit-learn offers number of most commonly used metrics, see [sklearn.metrics](https://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "\n",
    "- `kf_predicitions` contains out-of-sample predictions from individual splits (even though for now these are simply sample means)\n",
    "    * we can look at the overall score as well as specific splits (shows stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_results = pd.concat([\n",
    "    kf_predictions.groupby(['split']).apply(lambda x: sklearn.metrics.mean_squared_error(x[label], x['prediction']), include_groups=False),\n",
    "    kf_predictions.groupby(['split']).apply(lambda x: sklearn.metrics.mean_absolute_error(x[label], x['prediction']), include_groups=False),\n",
    "    kf_predictions.groupby(['split']).apply(lambda x: sklearn.metrics.r2_score(x[label], x['prediction']), include_groups=False),\n",
    "    ], axis = 1)\n",
    "split_results.columns = ['MSE','MAE', 'r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* now we have a basic modelling workflow implemented and we can fit an actual model\n",
    "* models/estimators in scikit-learn have standardized methods which provides great modularity\n",
    "    * we will see in a couple of minutes, that we can simply switch one model from another and reuse the whole pipeline!\n",
    "\n",
    "* `.fit(X,y)`\n",
    "    * `X` - sample matrix (n_samples, n_features)\n",
    "    * `y` - the target values y which (e.g. real numbers for regression, or ints for classification)\n",
    "        * `y` not specified for the regression tasks \n",
    "\n",
    "* `.predict(X)`\n",
    "    * \n",
    "\n",
    "* lets replace the sample mean with some econometrics model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "\n",
    "features = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
    "labels = ['MedHouseVal']\n",
    "\n",
    "\n",
    "kf_predictions = pd.DataFrame()\n",
    "i = 0\n",
    "for train_idx, test_idx in kf5.split(data):\n",
    "    print(f'split no. {i}')\n",
    "    train_data = data.loc[train_idx,:]\n",
    "    test_data = data.loc[test_idx,:]\n",
    "\n",
    "    # \"fitting\" part\n",
    "    model = sklearn.linear_model.LinearRegression()\n",
    "    model.fit(train_data[features], train_data[label])\n",
    "\n",
    "    # prediction part \n",
    "    test_data['prediction'] = model.predict(test_data[features])\n",
    "\n",
    "    # save predictions\n",
    "    test_data['split'] = i\n",
    "    kf_predictions = pd.concat([kf_predictions, test_data], axis = 0)\n",
    "    i = i + 1 \n",
    "\n",
    "split_results = pd.concat([\n",
    "    kf_predictions.groupby(['split']).apply(lambda x: sklearn.metrics.mean_squared_error(x[label], x['prediction']), include_groups=False),\n",
    "    kf_predictions.groupby(['split']).apply(lambda x: sklearn.metrics.mean_absolute_error(x[label], x['prediction']), include_groups=False),\n",
    "    kf_predictions.groupby(['split']).apply(lambda x: sklearn.metrics.r2_score(x[label], x['prediction']), include_groups=False),\n",
    "    ], axis = 1)\n",
    "split_results.columns = ['MSE','MAE', 'r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* using OLS instead of just looking at the mean helps a lot (of course)\n",
    "* before trying another model, let's put above code into a function so it is reusable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(data: pd.DataFrame, n_splits: int, features: List[str], label: str, model, model_args: Union[None,Dict]):\n",
    "    \"\"\"\n",
    "\n",
    "    Args: \n",
    "\n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    kfold_predictions = pd.DataFrame()\n",
    "\n",
    "    i = 0\n",
    "    kfold = sklearn.model_selection.KFold(n_splits=n_splits)\n",
    "\n",
    "    for train_idx, test_idx in kfold.split(data):\n",
    "\n",
    "        train_data = data.loc[train_idx,:]\n",
    "        test_data = data.loc[test_idx,:]\n",
    "\n",
    "        # model initialization\n",
    "        if model_args is not None:\n",
    "            split_model = model(**model_args)\n",
    "        else:\n",
    "            split_model = model()\n",
    "\n",
    "        # fit/estimate the model \n",
    "        split_model.fit(X = train_data[features], y = train_data[label])\n",
    "\n",
    "        # prediction on unseen data using fit model\n",
    "        test_data['prediction'] = split_model.predict(test_data[features])\n",
    "\n",
    "        # save split name and  predictions\n",
    "        test_data['split'] = i\n",
    "        kfold_predictions = pd.concat([kfold_predictions, test_data], axis = 0)\n",
    "        i = i + 1 \n",
    "\n",
    "    return kfold_predictions\n",
    "\n",
    "def eval_predicted(split_predictions: pd.DataFrame,label: str,eval_metrics = [sklearn.metrics.mean_squared_error, sklearn.metrics.r2_score]):\n",
    "\n",
    "    split_results = pd.concat([\n",
    "        split_predictions.groupby(['split']).apply(lambda x: eval_metric(x[label], x['prediction']), include_groups=False) for eval_metric in eval_metrics], axis = 1)\n",
    "    split_results.columns = [m.__name__ for m in eval_metrics]\n",
    "\n",
    "    return split_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could pack 2 functions below into separate function\n",
    "model_args = {'fit_intercept': True}\n",
    "predictions = train_predict(\n",
    "    data = data, n_splits = 5, \n",
    "    model = sklearn.linear_model.LinearRegression, \n",
    "    features = features, \n",
    "    label = label, \n",
    "    model_args = model_args)\n",
    "\n",
    "eval_predicted(split_predictions = predictions, label =  'MedHouseVal', eval_metrics= [sklearn.metrics.mean_squared_error,sklearn.metrics.mean_absolute_percentage_error])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* now let's switch sklearn model for LGBM!\n",
    "* our pipeline should still work (LGBM models also have `.fit()` and `.predict()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_args = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.1\n",
    "}\n",
    "\n",
    "predictions = train_predict(\n",
    "    data = data, n_splits = 5, \n",
    "    model = lightgbm.LGBMRegressor, \n",
    "    features = features, \n",
    "    label = label, \n",
    "    model_args= lgb_args)\n",
    "\n",
    "eval_predicted(split_predictions = predictions, label =  'MedHouseVal', eval_metrics= [sklearn.metrics.mean_squared_error,sklearn.metrics.mean_absolute_percentage_error])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2-times better with default hyperparamters!\n",
    "\n",
    "   * NOTE: we maybe should teach more trees at IES!\n",
    "\n",
    "* Let's look at another example, classification this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code from link\n",
    "\n",
    "https://inria.github.io/scikit-learn-mooc/python_scripts/datasets_california_housing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-3, 1, num=30)\n",
    "model = make_pipeline(StandardScaler(), RidgeCV(alphas=alphas))\n",
    "cv_results = cross_validate(\n",
    "    model,\n",
    "    data_raw.data,\n",
    "    data_raw.target,\n",
    "    return_estimator=True,\n",
    "    n_jobs=2,\n",
    "    # cv=5, # default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cv_results[\"test_score\"]\n",
    "print(f\"R2 score: {score.mean():.3f} ± {score.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "coefs = pd.DataFrame(\n",
    "    [est[-1].coef_ for est in cv_results[\"estimator\"]],\n",
    "    columns=data_raw.feature_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = {\"whiskers\": \"black\", \"medians\": \"black\", \"caps\": \"black\"}\n",
    "coefs.plot.box(vert=False, color=color)\n",
    "plt.axvline(x=0, ymin=-1, ymax=1, color=\"black\", linestyle=\"--\")\n",
    "_ = plt.title(\"Coefficients of Ridge models\\n via cross-validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we see from these boxplots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying recognizing hand-written digits\n",
    "\n",
    "* [example from scikit website](https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Training: %i\" % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(digits.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the images\n",
    "data = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.images.reshape((n_samples,-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier: a support vector classifier\n",
    "clf = svm.SVC(gamma=0.001)\n",
    "clf_alt = lightgbm.LGBMClassifier()\n",
    "\n",
    "# Split data into 50% train and 50% test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=0.5, shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn the digits on the train subset\n",
    "clf.fit(X_train, y_train)\n",
    "clf_alt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the value of the digit on the test subset\n",
    "predicted = clf.predict(X_test)\n",
    "predicted_alt = clf_alt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "\n",
    "for ax, image, prediction in zip(axes, X_test, predicted):\n",
    "    ax.set_axis_off()\n",
    "    image = image.reshape(8, 8)\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "\n",
    "for ax, image, prediction in zip(axes, X_test, predicted_alt):\n",
    "    ax.set_axis_off()\n",
    "    image = image.reshape(8, 8)\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report -> good resource -> https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers?oldformat=true\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, predicted_alt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, predicted)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "print(f\"Confusion matrix:\\n{disp.confusion_matrix}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
